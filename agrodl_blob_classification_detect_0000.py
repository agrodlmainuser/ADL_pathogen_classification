# -*- coding: utf-8 -*-
"""AgroDL_Blob_Classification_Detect_0000.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yQL7sfVl_oNXmn6UlPJ_SgkYmaQI03rh
"""

! pip install tensorflow --upgrade --user

# Import the required libraries
import tensorflow as tf
from tensorflow import keras
import tensorflow_hub as hub
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt
from IPython.display import HTML
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import datetime
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import shutil
import os
import cv2
import torch
import torchvision
from torchvision.io import read_image
from torchvision.utils import draw_bounding_boxes
import re
import uuid
from PIL import Image

#%cd /content/drive/MyDrive/Colab Notebooks

#from ADL_xml import ADL_Read_XML
#import xml.etree.ElementTree as ET

#script_parameters = ADL_Read_XML("AgroDL_Pepper_Tomato_Detect_0000")
#script_parameters.get_params()
#trained_model_root_dir = script_parameters.classification_model_save_root
#trained_model_name = script_parameters.trained_model_name

trained_model_root_dir = "/content/drive/MyDrive/Colab Notebooks/AgroML_Test_System/Clasification_Models"
trained_model_name = "exp3_mobilenet_v3_blob"

trained_model = keras.models.load_model(f"{trained_model_root_dir}/{trained_model_name}")
trained_model.summary()
class_names = os.listdir("/content/drive/MyDrive/Agroml/AgroML_Data/Diseases/blobs/Train")

class_names

"""This function is for performing the model on images to be tested. The output of the function is a list of corresponded lists, with pairs of name of detection, the detection of the tomur if exists and the confidence (1st list is the names, 2nd list is the detections and 3rd is the confidence)."""

# Testing images
def test_classification(model, folder_dir, IMAGE_SIZE):

  output_list = []
  conf_list = []
  class_list = []
  filenames_list = []
  #img_dir = "/content/drive/MyDrive/Agroml/Hagai/Hagai1/testC"
  for count,filename in enumerate(os.listdir(folder_dir)):
    if filename.endswith("mp4"):
      continue
    else:
      image_path = f'{folder_dir}/{filename}'
      new_img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
      img = tf.keras.preprocessing.image.img_to_array(new_img)
      img = np.expand_dims(img, axis=0)
      #print("Following is our prediction:")
      prediction = model.predict(img)
      d = prediction.flatten()
      j = d.max()
      for index,item in enumerate(d):
          if item == j:
              class_name = class_names[index]

      confidence = round(100 * j, 3)
      conf_list.append(confidence)
      class_list.append(class_name)
      filenames_list.append(filename)

  output_list.append(filenames_list)
  output_list.append(class_list)
  output_list.append(conf_list)

  return output_list
      # plt.figure(figsize = (4,4))
      #ax = plt.subplot(8, 5, count + 1)
      #plt.imshow(new_img)
      #plt.axis('off')
      #plt.title(f"A: {filename},\n P: {class_name}.\n Confidence: {confidence}%")

"""Fuzzy Logic function for "brownness" color filtering"""

def fuzzy_logic(img):

  for i in range(img.shape[0]):
    for j in range(img.shape[1]):
      pixel = img[i,j]
      if pixel[0] > pixel[1] > pixel[2] and  230 > pixel[0] > 75 and 75 > abs(pixel[1]-pixel[2]) > 17:
        #continue 
        img[i,j,0] = 255
        img[i,j,1] = 255
        img[i,j,2] = 255
      else:
        img[i,j,0] = 0
        img[i,j,1] = 0
        img[i,j,2] = 0
  
  return img

"""This Function takes an Image directory, preforms blob detections with fuzzy logic, corps the images to separte blobs and saves it to an output directory """

def blob_detection(input_path, output_path):

  ''' input_path = original images directory 
      output_path = output directory for all blob detections
  '''
  # input_path = original images directory 
  # output_path = output directory for all blob detections

  # Looping through the directory we want to apply blob detection on
  for i in os.listdir(input_path):

    read_img = cv2.imread(f'{input_path}/{i}')


    img_rgb = cv2.cvtColor(read_img, cv2.COLOR_BGR2RGB)

    # Applying Fuzzy Logic for "brownness" on the image
    fuzzy = fuzzy_logic(img_rgb)
    

    # Setting blob detections parameters
    params = cv2.SimpleBlobDetector_Params()
    params.filterByConvexity=False
    params.filterByColor = False
    params.filterByArea = True
    params.minArea = 20

    # Create a detector object
    detector = cv2.SimpleBlobDetector_create(params)
    # Make detections
    keypoints = detector.detect(fuzzy)
    # Draw a circle around the blob
    blank = np.zeros((1,1))
    im_with_keypoints = cv2.drawKeypoints(fuzzy, keypoints, blank ,(0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  

    # Extracting blobs coordinates
    keypoints_lst = []
    sec_lst =[]
    din_lst = []
    for j in range(len(keypoints)):

      x = keypoints[j].pt[0] #j is the index of the blob you want to get the position
      y = keypoints[j].pt[1]
      s = keypoints[j].size
      keypoints_lst.append(x)
      keypoints_lst.append(y)
      keypoints_lst.append(s)

    for count,blob in enumerate(keypoints_lst):
      count += 1
      din_lst.append(blob)
      if count%3 == 0:
        sec_lst.append(din_lst)
        din_lst = []


    # Crooping the images and resizing
    for coord in sec_lst:
      
      x_cent = round(coord[0])
      y_cent = round(coord[1])
      diameter = 64
      centroide = [x_cent,  y_cent]

      xmin = x_cent-diameter/2
      ymin = y_cent-diameter/2
      xmax = xmin+ diameter
      ymax = ymin+ diameter
      
      im = Image.open(f'{input_path}/{i}')
      im1 = im.crop((xmin, ymin, xmax, ymax))
      #dim = (64, 64)
      #resized = cv2.resize(np.array(im1), dim, interpolation = cv2.INTER_AREA)
      rgb = cv2.cvtColor(np.array(im1), cv2.COLOR_BGR2RGB)
      
      # Saving images to new directory
      img_name = os.path.join(output_path, '{}_blob_{}.jpg'.format(i ,uuid.uuid1()))
      cv2.imwrite(img_name, rgb)


  return keypoints

"""This Function takes the original image and draw a red circle around the blobs """

def blob_original_image(input_path, output_path):

  ''' input_path = original images directory 
      output_path = output directory for all blob detections
  '''
  # input_path = original images directory 
  # output_path = output directory for all blob detections

  # Looping through the directory we want to apply blob detection on
  for i in os.listdir(input_path):

    read_img = cv2.imread(f'{input_path}/{i}')
    
    img_rgb = cv2.cvtColor(read_img, cv2.COLOR_BGR2RGB)

    # Applying Fuzzy Logic for "brownness" on the image
    fuzzy = fuzzy_logic(img_rgb)

    # Setting blob detections parameters
    params = cv2.SimpleBlobDetector_Params()
    params.filterByConvexity=False
    params.filterByColor = False
    params.filterByArea = True
    params.minArea = 20

    # Create a detector object
    detector = cv2.SimpleBlobDetector_create(params)
    # Make detections
    keypoints = detector.detect(fuzzy)
    # Draw a circle around the blob
    blank = np.zeros((1,1))
    im_with_keypoints = cv2.drawKeypoints(read_img, keypoints, blank ,(0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  


    img_name = os.path.join(output_path, '{}_og_blob_{}.jpg'.format(i,uuid.uuid1()))
    cv2.imwrite(img_name, im_with_keypoints)

"""**Set I/O Paths**"""

path = "/content/drive/MyDrive/AgroDL/AgroDL_Data/Input/Leaf_classifications/extracted_leafs/p32.jpg"
dest_path = "/content/drive/MyDrive/AgroDL/AgroDL_Data/Input/Leaf_classifications/blobs"

"""**Detect Blobs**"""

blob_detection(path, dest_path)

"""**Set different path for original images with blobs drawings**"""

dest_path_og = "/content/drive/MyDrive/AgroDL/AgroDL_Data/Output/Leaf_classifications/blobs_with_original_image"

"""**Create Blobs with original images**"""

blob_original_image(path, dest_path_og)





"""**Testing Blbob Classification**"""

images_input = "/content/drive/MyDrive/AgroDL/AgroDL_Data/Input/Leaf_classifications/blobs"
results = test_classification(trained_model, images_input, 128)

results

"""**Dump Results to Pandas DataFrame**"""

df = pd.DataFrame(results)

df1 = df.T

df1 = df1.rename(columns={0: "Image", 1: "Disease", 2: "Score"})

df1

"""**Check unique values and counts**"""

df2 = df1.groupby('Disease')['Image'].nunique()

df2

"""**Extract the image name to list --> sec_lst**"""

names = []
sec_lst =[]
din_lst = []

for idx, row in df1.iterrows():
  #print(row[0])
  names.append(row[0].split('_')[0])
  names.append(row[1])
  names.append(row[2])

  
for count,blob in enumerate(names):
      count += 1
      din_lst.append(blob)
      if count%3 == 0:
        sec_lst.append(din_lst)
        din_lst = []

names

sec_lst

"""**Get the Splited name from the previous list and dump it in a new list --> splited_names**"""

splited_names = []
for i in sec_lst:

  splited_names.append(i[0])
  print(i[0])

splited_names

"""**Insert the names from splited_names as new column to our DataFrame**"""

df1.insert(0, 'Image_Name_Split', splited_names)
df1

"""**Sort the DataFrame by Image name**"""

df1.sort_values(by='Image', axis=0, inplace=True, ignore_index=True)
df1

df1

"""**Groupby the DataFrame by duplicates of Images(blobs) names**"""

nam = df1.groupby('Image_Name_Split')

groups = [nam.get_group(x) for x in nam.groups]



"""**Create a separte CSV file for each group with the relevant blobs**"""

for i,j in enumerate(groups):

  if len(groups[i]['Image_Name_Split']) == 1:
    #print('equal 1', i)
    n = groups[i]['Image_Name_Split'][-1:]
    n = n.to_list()
    j.to_csv(f"/content/drive/MyDrive/AgroDL/AgroDL_Data/Output/Leaf_classifications/blobs_csv/{i}_{n[0]}.csv")
    
  elif len(groups[i]['Image_Name_Split']) > 1:
    #print('not equal to 1',i)
    n = groups[i]['Image_Name_Split'][-1:]
    n = n.to_list()
    j.to_csv(f"/content/drive/MyDrive/AgroDL/AgroDL_Data/Output/Leaf_classifications/blobs_csv/{i}_{n[0]}.csv")











